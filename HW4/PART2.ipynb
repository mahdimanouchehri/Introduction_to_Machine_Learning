{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8Rjn_rVb8cC",
    "outputId": "4dc2f716-4edd-44bb-9204-f2c7c15e2ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Colab Notebooks/Mahdi\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/MyDrive/Colab \\Notebooks/Mahdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dNDloVa3brrI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "#Add Additional libraries here\n",
    "from torchvision import transforms as transforms\n",
    "from skimage.util import montage\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import vgg19,resnet50\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTH0CMa_cupG",
    "outputId": "730aac4c-e587-48a7-fb78-2095fbc34c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'COVID-CT' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/UCSD-AI4H/COVID-CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5g3uysIicxWa",
    "outputId": "88e00d0d-b608-4a6a-a4af-b18752543f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/Mahdi/COVID-CT/Images-processed\n"
     ]
    }
   ],
   "source": [
    "%cd COVID-CT/Images-processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnRA_YpboeFQ",
    "outputId": "13b4f906-e6bf-41fe-8938-36e6a6ec52f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  CT_COVID.zip\n",
      "replace CT_COVID/2020.03.01.20029769-p21-73_1%1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
      "Archive:  CT_NonCOVID.zip\n",
      "replace CT_NonCOVID/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "!unzip CT_COVID.zip\n",
    "!unzip CT_NonCOVID.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiIps1R8pveZ",
    "outputId": "c3cd49c8-4951-4d8f-c298-4ee033b2f1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/Mahdi/COVID-CT\n"
     ]
    }
   ],
   "source": [
    "#cd back to the main folder\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8ow6bMIBc30M"
   },
   "outputs": [],
   "source": [
    "covid_files_path = 'Images-processed/CT_COVID/'\n",
    "covid_files      = [os.path.join(covid_files_path, x) for x in os.listdir(covid_files_path)]\n",
    "non_covid_files_path = 'Images-processed/CT_NonCOVID/'\n",
    "non_covid_files      = [os.path.join(non_covid_files_path, x) for x in os.listdir(non_covid_files_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ra-umsYpc4n8"
   },
   "outputs": [],
   "source": [
    "covid_images    =  [cv2.imread(x) for x in random.sample(covid_files, 3)]\n",
    "non_covid_images = [cv2.imread(x) for x in random.sample(non_covid_files, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "7UxSjj7LgUOI",
    "outputId": "c5e43aa2-edbf-4f71-b089-12b2fdd61626"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, image in enumerate(covid_images):\n",
    "    plt.subplot(len(covid_images) / 3+1, 3, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "h89f9zQleNoi",
    "outputId": "3d00b611-0f5e-4ae5-f8a4-06283f2d546a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, image in enumerate(non_covid_images):\n",
    "    plt.subplot(len(non_covid_images) / 3 + 1, 3, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4KBN4VCGuwxt"
   },
   "outputs": [],
   "source": [
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aAgCpZYpu0cd"
   },
   "outputs": [],
   "source": [
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, classes, covid_files, non_covid_files, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.files_path = [non_covid_files, covid_files]\n",
    "        self.image_list = []\n",
    "\n",
    "        # read the files from data split text files\n",
    "        covid_files = read_txt(covid_files)\n",
    "        non_covid_files = read_txt(non_covid_files)\n",
    "\n",
    "        # combine the positive and negative files into a cummulative files list\n",
    "        for cls_index in range(len(self.classes)):\n",
    "            \n",
    "            class_files = [[os.path.join(self.root_dir, self.classes[cls_index], x), cls_index] \\\n",
    "                            for x in read_txt(self.files_path[cls_index])]\n",
    "            self.image_list += class_files\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_list[idx][0]\n",
    "        \n",
    "        # Read the image\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = int(self.image_list[idx][1])\n",
    "\n",
    "        data = {'img':   image,\n",
    "                'label': label,\n",
    "                'paths' : path}\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UO3i6rEAwKe6"
   },
   "outputs": [],
   "source": [
    "#The normalization article refers to these numbers mean=[0.485, 0.456, 0.406] and standard = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pk9suQCxu3qo"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e4LRizoQvHPC"
   },
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),  \n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BJhe9e2zvJ78"
   },
   "outputs": [],
   "source": [
    "val_transformer = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TmhXKZiOwgcG"
   },
   "outputs": [],
   "source": [
    "batchsize = 8\n",
    "\n",
    "trainset = CovidCTDataset(root_dir='Images-processed/',\n",
    "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
    "                          covid_files='Data-split/COVID/trainCT_COVID.txt',\n",
    "                          non_covid_files='Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                          transform= train_transformer)\n",
    "valset = CovidCTDataset(root_dir='Images-processed/',\n",
    "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
    "                          covid_files='Data-split/COVID/valCT_COVID.txt',\n",
    "                          non_covid_files = 'Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "testset = CovidCTDataset(root_dir='Images-processed/',\n",
    "                          classes = ['CT_NonCOVID', 'CT_COVID'],\n",
    "                          covid_files='Data-split/COVID/testCT_COVID.txt',\n",
    "                          non_covid_files='Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                          transform= val_transformer)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dXI1oRr0w2XW"
   },
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8xs18E8w2GxU"
   },
   "outputs": [],
   "source": [
    "# model.classifier[6] = nn.Linear(in_features=4096, out_features=2);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yJSSNeid2kPc"
   },
   "outputs": [],
   "source": [
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({}%)] \\t Train Loss: {}'.format(epoch, batch_index, len(train_loader),100.0 * batch_index / len(train_loader), loss.item() / bs))\n",
    "    \n",
    "    print('\\n Train set: Average loss: {}, Accuracy: {}/{} ({}%)\\n'.format(train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),100.0 * train_correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cjIewKW69CTO"
   },
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "          \n",
    "    return targetlist, scorelist, predlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rSxjn4-Z2IqL"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IjgQ7t-G3aON"
   },
   "outputs": [],
   "source": [
    "bs = 10\n",
    "votenum = 10\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "MKtP3zQ3PqIs"
   },
   "outputs": [],
   "source": [
    "#number epoch\n",
    "total_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XTu6KOP2Rec",
    "outputId": "f309e17e-8595-4914-c02c-aa96cd1f1cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54 (0.0%)] \t Train Loss: 0.883992862701416\n",
      "Train Epoch: 1 [10/54 (18.51851851851852%)] \t Train Loss: 0.5309305667877198\n",
      "Train Epoch: 1 [20/54 (37.03703703703704%)] \t Train Loss: 0.4471578121185303\n",
      "Train Epoch: 1 [30/54 (55.55555555555556%)] \t Train Loss: 0.08889859914779663\n",
      "Train Epoch: 1 [40/54 (74.07407407407408%)] \t Train Loss: 0.19574081897735596\n",
      "Train Epoch: 1 [50/54 (92.5925925925926%)] \t Train Loss: 0.14797719717025756\n",
      "\n",
      " Train set: Average loss: 0.4078804850578308, Accuracy: 231/425 (54.35294117647059%)\n",
      "\n",
      "Train Epoch: 2 [0/54 (0.0%)] \t Train Loss: 0.018654680252075194\n",
      "Train Epoch: 2 [10/54 (18.51851851851852%)] \t Train Loss: 0.042966237664222716\n",
      "Train Epoch: 2 [20/54 (37.03703703703704%)] \t Train Loss: 0.030092856287956236\n",
      "Train Epoch: 2 [30/54 (55.55555555555556%)] \t Train Loss: 0.008714397996664047\n",
      "Train Epoch: 2 [40/54 (74.07407407407408%)] \t Train Loss: 0.03152499198913574\n",
      "Train Epoch: 2 [50/54 (92.5925925925926%)] \t Train Loss: 0.007695122063159943\n",
      "\n",
      " Train set: Average loss: 0.055968496948480606, Accuracy: 366/425 (86.11764705882354%)\n",
      "\n",
      "Train Epoch: 3 [0/54 (0.0%)] \t Train Loss: 0.005960208922624588\n",
      "Train Epoch: 3 [10/54 (18.51851851851852%)] \t Train Loss: 0.020753927528858185\n",
      "Train Epoch: 3 [20/54 (37.03703703703704%)] \t Train Loss: 0.0067431718111038205\n",
      "Train Epoch: 3 [30/54 (55.55555555555556%)] \t Train Loss: 0.13947556018829346\n",
      "Train Epoch: 3 [40/54 (74.07407407407408%)] \t Train Loss: 0.009222131967544556\n",
      "Train Epoch: 3 [50/54 (92.5925925925926%)] \t Train Loss: 0.009446272253990173\n",
      "\n",
      " Train set: Average loss: 0.0414513498544693, Accuracy: 376/425 (88.47058823529412%)\n",
      "\n",
      "Train Epoch: 4 [0/54 (0.0%)] \t Train Loss: 0.015786372125148773\n",
      "Train Epoch: 4 [10/54 (18.51851851851852%)] \t Train Loss: 0.046793031692504886\n",
      "Train Epoch: 4 [20/54 (37.03703703703704%)] \t Train Loss: 0.002174488827586174\n",
      "Train Epoch: 4 [30/54 (55.55555555555556%)] \t Train Loss: 0.0145546555519104\n",
      "Train Epoch: 4 [40/54 (74.07407407407408%)] \t Train Loss: 0.032277056574821474\n",
      "Train Epoch: 4 [50/54 (92.5925925925926%)] \t Train Loss: 0.03333604335784912\n",
      "\n",
      " Train set: Average loss: 0.02671106345951557, Accuracy: 385/425 (90.58823529411765%)\n",
      "\n",
      "Train Epoch: 5 [0/54 (0.0%)] \t Train Loss: 0.002762084640562534\n",
      "Train Epoch: 5 [10/54 (18.51851851851852%)] \t Train Loss: 0.04677868187427521\n",
      "Train Epoch: 5 [20/54 (37.03703703703704%)] \t Train Loss: 0.0009386686608195305\n",
      "Train Epoch: 5 [30/54 (55.55555555555556%)] \t Train Loss: 0.07878463864326476\n",
      "Train Epoch: 5 [40/54 (74.07407407407408%)] \t Train Loss: 0.031422606110572814\n",
      "Train Epoch: 5 [50/54 (92.5925925925926%)] \t Train Loss: 0.0021515509113669397\n",
      "\n",
      " Train set: Average loss: 0.025408582761883736, Accuracy: 391/425 (92.0%)\n",
      "\n",
      "Train Epoch: 6 [0/54 (0.0%)] \t Train Loss: 0.01165469065308571\n",
      "Train Epoch: 6 [10/54 (18.51851851851852%)] \t Train Loss: 0.006327474117279052\n",
      "Train Epoch: 6 [20/54 (37.03703703703704%)] \t Train Loss: 0.0035924069583415986\n",
      "Train Epoch: 6 [30/54 (55.55555555555556%)] \t Train Loss: 0.013534772396087646\n",
      "Train Epoch: 6 [40/54 (74.07407407407408%)] \t Train Loss: 0.0033085662871599197\n",
      "Train Epoch: 6 [50/54 (92.5925925925926%)] \t Train Loss: 0.010117602348327637\n",
      "\n",
      " Train set: Average loss: 0.02693226933479309, Accuracy: 400/425 (94.11764705882354%)\n",
      "\n",
      "Train Epoch: 7 [0/54 (0.0%)] \t Train Loss: 0.03266406655311584\n",
      "Train Epoch: 7 [10/54 (18.51851851851852%)] \t Train Loss: 0.003936357423663139\n",
      "Train Epoch: 7 [20/54 (37.03703703703704%)] \t Train Loss: 0.058430933952331544\n",
      "Train Epoch: 7 [30/54 (55.55555555555556%)] \t Train Loss: 0.01852177530527115\n",
      "Train Epoch: 7 [40/54 (74.07407407407408%)] \t Train Loss: 0.0028020726516842843\n",
      "Train Epoch: 7 [50/54 (92.5925925925926%)] \t Train Loss: 0.024487727880477907\n",
      "\n",
      " Train set: Average loss: 0.028786905109882355, Accuracy: 397/425 (93.41176470588235%)\n",
      "\n",
      "Train Epoch: 8 [0/54 (0.0%)] \t Train Loss: 0.013341015577316285\n",
      "Train Epoch: 8 [10/54 (18.51851851851852%)] \t Train Loss: 0.00045910421758890154\n",
      "Train Epoch: 8 [20/54 (37.03703703703704%)] \t Train Loss: 0.015880346298217773\n",
      "Train Epoch: 8 [30/54 (55.55555555555556%)] \t Train Loss: 0.01999572813510895\n",
      "Train Epoch: 8 [40/54 (74.07407407407408%)] \t Train Loss: 0.08711751699447631\n",
      "Train Epoch: 8 [50/54 (92.5925925925926%)] \t Train Loss: 0.0011441239155828952\n",
      "\n",
      " Train set: Average loss: 0.021443337202072144, Accuracy: 397/425 (93.41176470588235%)\n",
      "\n",
      "Train Epoch: 9 [0/54 (0.0%)] \t Train Loss: 0.026587936282157897\n",
      "Train Epoch: 9 [10/54 (18.51851851851852%)] \t Train Loss: 0.0024923916906118395\n",
      "Train Epoch: 9 [20/54 (37.03703703703704%)] \t Train Loss: 0.005075820162892342\n",
      "Train Epoch: 9 [30/54 (55.55555555555556%)] \t Train Loss: 0.022045725584030153\n",
      "Train Epoch: 9 [40/54 (74.07407407407408%)] \t Train Loss: 0.0014298241585493088\n",
      "Train Epoch: 9 [50/54 (92.5925925925926%)] \t Train Loss: 0.0023026961833238603\n",
      "\n",
      " Train set: Average loss: 0.012587104924023151, Accuracy: 412/425 (96.94117647058823%)\n",
      "\n",
      "Train Epoch: 10 [0/54 (0.0%)] \t Train Loss: 0.015169794857501983\n",
      "Train Epoch: 10 [10/54 (18.51851851851852%)] \t Train Loss: 0.010086765885353089\n",
      "Train Epoch: 10 [20/54 (37.03703703703704%)] \t Train Loss: 0.0027537308633327484\n",
      "Train Epoch: 10 [30/54 (55.55555555555556%)] \t Train Loss: 0.041173940896987914\n",
      "Train Epoch: 10 [40/54 (74.07407407407408%)] \t Train Loss: 0.00025051115080714225\n",
      "Train Epoch: 10 [50/54 (92.5925925925926%)] \t Train Loss: 0.03440882861614227\n",
      "\n",
      " Train set: Average loss: 0.02433617413043976, Accuracy: 399/425 (93.88235294117646%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 45 FN= 13 FP= 13\n",
      "TP+FP 60\n",
      "precision 0.7833333333333333\n",
      "recall 0.7833333333333333\n",
      "F1 0.7833333333333333\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7795977011494253\n",
      "AUC 0.8514367816091953\n",
      "\n",
      " The epoch is 10, average recall: 0.7833333333333333, average precision: 0.7833333333333333,average F1: 0.7833333333333333, average accuracy: 0.7796610169491526, average AUC: 0.8514367816091953\n",
      "Train Epoch: 11 [0/54 (0.0%)] \t Train Loss: 0.0018737925216555595\n",
      "Train Epoch: 11 [10/54 (18.51851851851852%)] \t Train Loss: 0.02743205428123474\n",
      "Train Epoch: 11 [20/54 (37.03703703703704%)] \t Train Loss: 0.015672554075717927\n",
      "Train Epoch: 11 [30/54 (55.55555555555556%)] \t Train Loss: 0.019036117196083068\n",
      "Train Epoch: 11 [40/54 (74.07407407407408%)] \t Train Loss: 0.006579373776912689\n",
      "Train Epoch: 11 [50/54 (92.5925925925926%)] \t Train Loss: 0.011350448429584502\n",
      "\n",
      " Train set: Average loss: 0.020797334611415863, Accuracy: 400/425 (94.11764705882354%)\n",
      "\n",
      "Train Epoch: 12 [0/54 (0.0%)] \t Train Loss: 0.0008390021510422229\n",
      "Train Epoch: 12 [10/54 (18.51851851851852%)] \t Train Loss: 0.004149190708994865\n",
      "Train Epoch: 12 [20/54 (37.03703703703704%)] \t Train Loss: 0.0027957186102867126\n",
      "Train Epoch: 12 [30/54 (55.55555555555556%)] \t Train Loss: 0.001044740155339241\n",
      "Train Epoch: 12 [40/54 (74.07407407407408%)] \t Train Loss: 0.012109729647636413\n",
      "Train Epoch: 12 [50/54 (92.5925925925926%)] \t Train Loss: 0.014281553030014039\n",
      "\n",
      " Train set: Average loss: 0.014947837218642235, Accuracy: 409/425 (96.23529411764706%)\n",
      "\n",
      "Train Epoch: 13 [0/54 (0.0%)] \t Train Loss: 0.0056694217026233675\n",
      "Train Epoch: 13 [10/54 (18.51851851851852%)] \t Train Loss: 0.0012434940785169602\n",
      "Train Epoch: 13 [20/54 (37.03703703703704%)] \t Train Loss: 0.004168698191642761\n",
      "Train Epoch: 13 [30/54 (55.55555555555556%)] \t Train Loss: 0.1646231770515442\n",
      "Train Epoch: 13 [40/54 (74.07407407407408%)] \t Train Loss: 0.0005206362344324589\n",
      "Train Epoch: 13 [50/54 (92.5925925925926%)] \t Train Loss: 0.0005481902044266462\n",
      "\n",
      " Train set: Average loss: 0.022559799253940582, Accuracy: 398/425 (93.6470588235294%)\n",
      "\n",
      "Train Epoch: 14 [0/54 (0.0%)] \t Train Loss: 0.006441078335046768\n",
      "Train Epoch: 14 [10/54 (18.51851851851852%)] \t Train Loss: 0.0008546857163310051\n",
      "Train Epoch: 14 [20/54 (37.03703703703704%)] \t Train Loss: 0.007487031072378159\n",
      "Train Epoch: 14 [30/54 (55.55555555555556%)] \t Train Loss: 0.017770345509052276\n",
      "Train Epoch: 14 [40/54 (74.07407407407408%)] \t Train Loss: 0.0016662606969475747\n",
      "Train Epoch: 14 [50/54 (92.5925925925926%)] \t Train Loss: 0.005099525302648544\n",
      "\n",
      " Train set: Average loss: 0.013817297294735909, Accuracy: 411/425 (96.70588235294117%)\n",
      "\n",
      "Train Epoch: 15 [0/54 (0.0%)] \t Train Loss: 0.013211838901042938\n",
      "Train Epoch: 15 [10/54 (18.51851851851852%)] \t Train Loss: 0.0012481987476348877\n",
      "Train Epoch: 15 [20/54 (37.03703703703704%)] \t Train Loss: 0.0008787892758846283\n",
      "Train Epoch: 15 [30/54 (55.55555555555556%)] \t Train Loss: 0.000993199460208416\n",
      "Train Epoch: 15 [40/54 (74.07407407407408%)] \t Train Loss: 0.0013385013677179813\n",
      "Train Epoch: 15 [50/54 (92.5925925925926%)] \t Train Loss: 0.004514482244849205\n",
      "\n",
      " Train set: Average loss: 0.016235308721661568, Accuracy: 405/425 (95.29411764705883%)\n",
      "\n",
      "Train Epoch: 16 [0/54 (0.0%)] \t Train Loss: 0.005625341460108757\n",
      "Train Epoch: 16 [10/54 (18.51851851851852%)] \t Train Loss: 0.052499419450759886\n",
      "Train Epoch: 16 [20/54 (37.03703703703704%)] \t Train Loss: 0.01861427426338196\n",
      "Train Epoch: 16 [30/54 (55.55555555555556%)] \t Train Loss: 0.08608280420303345\n",
      "Train Epoch: 16 [40/54 (74.07407407407408%)] \t Train Loss: 0.01947944760322571\n",
      "Train Epoch: 16 [50/54 (92.5925925925926%)] \t Train Loss: 0.000882562529295683\n",
      "\n",
      " Train set: Average loss: 0.028597384691238403, Accuracy: 395/425 (92.94117647058823%)\n",
      "\n",
      "Train Epoch: 17 [0/54 (0.0%)] \t Train Loss: 0.015785157680511475\n",
      "Train Epoch: 17 [10/54 (18.51851851851852%)] \t Train Loss: 0.0579224944114685\n",
      "Train Epoch: 17 [20/54 (37.03703703703704%)] \t Train Loss: 0.0023918647319078447\n",
      "Train Epoch: 17 [30/54 (55.55555555555556%)] \t Train Loss: 0.08848214745521546\n",
      "Train Epoch: 17 [40/54 (74.07407407407408%)] \t Train Loss: 0.006401487439870834\n",
      "Train Epoch: 17 [50/54 (92.5925925925926%)] \t Train Loss: 0.0017550382763147354\n",
      "\n",
      " Train set: Average loss: 0.01755349524319172, Accuracy: 406/425 (95.52941176470588%)\n",
      "\n",
      "Train Epoch: 18 [0/54 (0.0%)] \t Train Loss: 0.001989257708191872\n",
      "Train Epoch: 18 [10/54 (18.51851851851852%)] \t Train Loss: 0.0009646636433899402\n",
      "Train Epoch: 18 [20/54 (37.03703703703704%)] \t Train Loss: 0.0011063103564083576\n",
      "Train Epoch: 18 [30/54 (55.55555555555556%)] \t Train Loss: 0.0058665558695793155\n",
      "Train Epoch: 18 [40/54 (74.07407407407408%)] \t Train Loss: 0.0004670472349971533\n",
      "Train Epoch: 18 [50/54 (92.5925925925926%)] \t Train Loss: 0.029440441727638246\n",
      "\n",
      " Train set: Average loss: 0.008870313875377178, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "Train Epoch: 19 [0/54 (0.0%)] \t Train Loss: 0.0008474166505038738\n",
      "Train Epoch: 19 [10/54 (18.51851851851852%)] \t Train Loss: 0.03451616764068603\n",
      "Train Epoch: 19 [20/54 (37.03703703703704%)] \t Train Loss: 0.003762401267886162\n",
      "Train Epoch: 19 [30/54 (55.55555555555556%)] \t Train Loss: 0.03416339159011841\n",
      "Train Epoch: 19 [40/54 (74.07407407407408%)] \t Train Loss: 0.00429500974714756\n",
      "Train Epoch: 19 [50/54 (92.5925925925926%)] \t Train Loss: 0.00103859705850482\n",
      "\n",
      " Train set: Average loss: 0.01620929315686226, Accuracy: 403/425 (94.82352941176471%)\n",
      "\n",
      "Train Epoch: 20 [0/54 (0.0%)] \t Train Loss: 0.0018903516232967378\n",
      "Train Epoch: 20 [10/54 (18.51851851851852%)] \t Train Loss: 0.0005770470947027206\n",
      "Train Epoch: 20 [20/54 (37.03703703703704%)] \t Train Loss: 0.0003839487675577402\n",
      "Train Epoch: 20 [30/54 (55.55555555555556%)] \t Train Loss: 0.0029173048213124277\n",
      "Train Epoch: 20 [40/54 (74.07407407407408%)] \t Train Loss: 0.013207925856113434\n",
      "Train Epoch: 20 [50/54 (92.5925925925926%)] \t Train Loss: 0.006280839443206787\n",
      "\n",
      " Train set: Average loss: 0.013360729441046715, Accuracy: 412/425 (96.94117647058823%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 53 TN= 44 FN= 7 FP= 14\n",
      "TP+FP 67\n",
      "precision 0.7910447761194029\n",
      "recall 0.8833333333333333\n",
      "F1 0.8346456692913385\n",
      "acc 0.8220338983050848\n",
      "AUCp 0.8209770114942528\n",
      "AUC 0.8577586206896551\n",
      "\n",
      " The epoch is 20, average recall: 0.8833333333333333, average precision: 0.7910447761194029,average F1: 0.8346456692913385, average accuracy: 0.8220338983050848, average AUC: 0.8577586206896551\n",
      "Train Epoch: 21 [0/54 (0.0%)] \t Train Loss: 0.0014323742128908635\n",
      "Train Epoch: 21 [10/54 (18.51851851851852%)] \t Train Loss: 0.013273434340953827\n",
      "Train Epoch: 21 [20/54 (37.03703703703704%)] \t Train Loss: 0.00014528606552630663\n",
      "Train Epoch: 21 [30/54 (55.55555555555556%)] \t Train Loss: 0.022874456644058228\n",
      "Train Epoch: 21 [40/54 (74.07407407407408%)] \t Train Loss: 9.9270511418581e-05\n",
      "Train Epoch: 21 [50/54 (92.5925925925926%)] \t Train Loss: 0.0005172556266188622\n",
      "\n",
      " Train set: Average loss: 0.01165743824094534, Accuracy: 408/425 (96.0%)\n",
      "\n",
      "Train Epoch: 22 [0/54 (0.0%)] \t Train Loss: 0.00199808981269598\n",
      "Train Epoch: 22 [10/54 (18.51851851851852%)] \t Train Loss: 0.000493408739566803\n",
      "Train Epoch: 22 [20/54 (37.03703703703704%)] \t Train Loss: 0.0017187608405947684\n",
      "Train Epoch: 22 [30/54 (55.55555555555556%)] \t Train Loss: 0.003111167810857296\n",
      "Train Epoch: 22 [40/54 (74.07407407407408%)] \t Train Loss: 0.0021625658497214316\n",
      "Train Epoch: 22 [50/54 (92.5925925925926%)] \t Train Loss: 0.005141065269708633\n",
      "\n",
      " Train set: Average loss: 0.01812048815190792, Accuracy: 411/425 (96.70588235294117%)\n",
      "\n",
      "Train Epoch: 23 [0/54 (0.0%)] \t Train Loss: 0.0028958704322576525\n",
      "Train Epoch: 23 [10/54 (18.51851851851852%)] \t Train Loss: 0.018312039971351623\n",
      "Train Epoch: 23 [20/54 (37.03703703703704%)] \t Train Loss: 0.00200318805873394\n",
      "Train Epoch: 23 [30/54 (55.55555555555556%)] \t Train Loss: 0.04032994508743286\n",
      "Train Epoch: 23 [40/54 (74.07407407407408%)] \t Train Loss: 0.017390900850296022\n",
      "Train Epoch: 23 [50/54 (92.5925925925926%)] \t Train Loss: 0.005499206855893135\n",
      "\n",
      " Train set: Average loss: 0.015334798954427242, Accuracy: 406/425 (95.52941176470588%)\n",
      "\n",
      "Train Epoch: 24 [0/54 (0.0%)] \t Train Loss: 0.0006113228388130665\n",
      "Train Epoch: 24 [10/54 (18.51851851851852%)] \t Train Loss: 0.010620878636837005\n",
      "Train Epoch: 24 [20/54 (37.03703703703704%)] \t Train Loss: 0.004383249953389168\n",
      "Train Epoch: 24 [30/54 (55.55555555555556%)] \t Train Loss: 0.008322399109601974\n",
      "Train Epoch: 24 [40/54 (74.07407407407408%)] \t Train Loss: 0.0016225021332502364\n",
      "Train Epoch: 24 [50/54 (92.5925925925926%)] \t Train Loss: 0.00403260700404644\n",
      "\n",
      " Train set: Average loss: 0.012182062491774559, Accuracy: 409/425 (96.23529411764706%)\n",
      "\n",
      "Train Epoch: 25 [0/54 (0.0%)] \t Train Loss: 0.00030736830085515977\n",
      "Train Epoch: 25 [10/54 (18.51851851851852%)] \t Train Loss: 0.0012727949768304824\n",
      "Train Epoch: 25 [20/54 (37.03703703703704%)] \t Train Loss: 0.0007700303569436074\n",
      "Train Epoch: 25 [30/54 (55.55555555555556%)] \t Train Loss: 0.0005579182412475348\n",
      "Train Epoch: 25 [40/54 (74.07407407407408%)] \t Train Loss: 0.05800700783729553\n",
      "Train Epoch: 25 [50/54 (92.5925925925926%)] \t Train Loss: 0.005313335731625557\n",
      "\n",
      " Train set: Average loss: 0.007370457984507084, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 26 [0/54 (0.0%)] \t Train Loss: 0.0593658447265625\n",
      "Train Epoch: 26 [10/54 (18.51851851851852%)] \t Train Loss: 0.000862119160592556\n",
      "Train Epoch: 26 [20/54 (37.03703703703704%)] \t Train Loss: 0.0652963399887085\n",
      "Train Epoch: 26 [30/54 (55.55555555555556%)] \t Train Loss: 0.0002442094264551997\n",
      "Train Epoch: 26 [40/54 (74.07407407407408%)] \t Train Loss: 0.00031423012260347607\n",
      "Train Epoch: 26 [50/54 (92.5925925925926%)] \t Train Loss: 0.0019226565957069397\n",
      "\n",
      " Train set: Average loss: 0.012423106469213963, Accuracy: 409/425 (96.23529411764706%)\n",
      "\n",
      "Train Epoch: 27 [0/54 (0.0%)] \t Train Loss: 0.030690541863441466\n",
      "Train Epoch: 27 [10/54 (18.51851851851852%)] \t Train Loss: 0.010262081027030944\n",
      "Train Epoch: 27 [20/54 (37.03703703703704%)] \t Train Loss: 0.0039413835853338245\n",
      "Train Epoch: 27 [30/54 (55.55555555555556%)] \t Train Loss: 0.0037084735929965975\n",
      "Train Epoch: 27 [40/54 (74.07407407407408%)] \t Train Loss: 0.0013984335586428643\n",
      "Train Epoch: 27 [50/54 (92.5925925925926%)] \t Train Loss: 0.0008301839232444763\n",
      "\n",
      " Train set: Average loss: 0.012911010533571243, Accuracy: 410/425 (96.47058823529412%)\n",
      "\n",
      "Train Epoch: 28 [0/54 (0.0%)] \t Train Loss: 0.001706155389547348\n",
      "Train Epoch: 28 [10/54 (18.51851851851852%)] \t Train Loss: 0.010692949593067168\n",
      "Train Epoch: 28 [20/54 (37.03703703703704%)] \t Train Loss: 0.0008066610433161258\n",
      "Train Epoch: 28 [30/54 (55.55555555555556%)] \t Train Loss: 0.004196454584598541\n",
      "Train Epoch: 28 [40/54 (74.07407407407408%)] \t Train Loss: 0.010669424384832382\n",
      "Train Epoch: 28 [50/54 (92.5925925925926%)] \t Train Loss: 0.0010530324652791023\n",
      "\n",
      " Train set: Average loss: 0.01035510003566742, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "Train Epoch: 29 [0/54 (0.0%)] \t Train Loss: 0.0005459816660732031\n",
      "Train Epoch: 29 [10/54 (18.51851851851852%)] \t Train Loss: 0.005454781651496887\n",
      "Train Epoch: 29 [20/54 (37.03703703703704%)] \t Train Loss: 0.002718854695558548\n",
      "Train Epoch: 29 [30/54 (55.55555555555556%)] \t Train Loss: 0.15329103469848632\n",
      "Train Epoch: 29 [40/54 (74.07407407407408%)] \t Train Loss: 0.0024124927818775176\n",
      "Train Epoch: 29 [50/54 (92.5925925925926%)] \t Train Loss: 0.018909770250320434\n",
      "\n",
      " Train set: Average loss: 0.019058506935834885, Accuracy: 404/425 (95.05882352941177%)\n",
      "\n",
      "Train Epoch: 30 [0/54 (0.0%)] \t Train Loss: 0.005209909752011299\n",
      "Train Epoch: 30 [10/54 (18.51851851851852%)] \t Train Loss: 0.00142993638291955\n",
      "Train Epoch: 30 [20/54 (37.03703703703704%)] \t Train Loss: 0.006607954949140548\n",
      "Train Epoch: 30 [30/54 (55.55555555555556%)] \t Train Loss: 0.00040381918661296367\n",
      "Train Epoch: 30 [40/54 (74.07407407407408%)] \t Train Loss: 0.0011603609658777715\n",
      "Train Epoch: 30 [50/54 (92.5925925925926%)] \t Train Loss: 0.00014351431746035815\n",
      "\n",
      " Train set: Average loss: 0.007413030602037907, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 44 FN= 17 FP= 14\n",
      "TP+FP 57\n",
      "precision 0.7543859649122807\n",
      "recall 0.7166666666666667\n",
      "F1 0.735042735042735\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7376436781609196\n",
      "AUC 0.8471264367816091\n",
      "\n",
      " The epoch is 30, average recall: 0.7166666666666667, average precision: 0.7543859649122807,average F1: 0.735042735042735, average accuracy: 0.7372881355932204, average AUC: 0.8471264367816091\n",
      "Train Epoch: 31 [0/54 (0.0%)] \t Train Loss: 0.04942139089107513\n",
      "Train Epoch: 31 [10/54 (18.51851851851852%)] \t Train Loss: 0.0007932976819574833\n",
      "Train Epoch: 31 [20/54 (37.03703703703704%)] \t Train Loss: 7.101985975168645e-05\n",
      "Train Epoch: 31 [30/54 (55.55555555555556%)] \t Train Loss: 0.00018608132377266883\n",
      "Train Epoch: 31 [40/54 (74.07407407407408%)] \t Train Loss: 0.00013199658133089542\n",
      "Train Epoch: 31 [50/54 (92.5925925925926%)] \t Train Loss: 0.004274939373135567\n",
      "\n",
      " Train set: Average loss: 0.009782255627214909, Accuracy: 414/425 (97.41176470588235%)\n",
      "\n",
      "Train Epoch: 32 [0/54 (0.0%)] \t Train Loss: 0.0014142146334052085\n",
      "Train Epoch: 32 [10/54 (18.51851851851852%)] \t Train Loss: 0.0016043730080127715\n",
      "Train Epoch: 32 [20/54 (37.03703703703704%)] \t Train Loss: 0.0005019012372940779\n",
      "Train Epoch: 32 [30/54 (55.55555555555556%)] \t Train Loss: 0.00013617994263768197\n",
      "Train Epoch: 32 [40/54 (74.07407407407408%)] \t Train Loss: 0.0003212834009900689\n",
      "Train Epoch: 32 [50/54 (92.5925925925926%)] \t Train Loss: 0.0001361645176075399\n",
      "\n",
      " Train set: Average loss: 0.003595871152356267, Accuracy: 425/425 (100.0%)\n",
      "\n",
      "Train Epoch: 33 [0/54 (0.0%)] \t Train Loss: 0.017551852762699126\n",
      "Train Epoch: 33 [10/54 (18.51851851851852%)] \t Train Loss: 0.0007066192571073771\n",
      "Train Epoch: 33 [20/54 (37.03703703703704%)] \t Train Loss: 0.000644927704706788\n",
      "Train Epoch: 33 [30/54 (55.55555555555556%)] \t Train Loss: 0.0015147139318287372\n",
      "Train Epoch: 33 [40/54 (74.07407407407408%)] \t Train Loss: 0.0027588991448283195\n",
      "Train Epoch: 33 [50/54 (92.5925925925926%)] \t Train Loss: 0.0035644035786390306\n",
      "\n",
      " Train set: Average loss: 0.011021636426448822, Accuracy: 415/425 (97.6470588235294%)\n",
      "\n",
      "Train Epoch: 34 [0/54 (0.0%)] \t Train Loss: 0.0023673050105571746\n",
      "Train Epoch: 34 [10/54 (18.51851851851852%)] \t Train Loss: 0.0023984871804714203\n",
      "Train Epoch: 34 [20/54 (37.03703703703704%)] \t Train Loss: 9.680401417426765e-05\n",
      "Train Epoch: 34 [30/54 (55.55555555555556%)] \t Train Loss: 0.0009737370535731315\n",
      "Train Epoch: 34 [40/54 (74.07407407407408%)] \t Train Loss: 0.0008699942380189895\n",
      "Train Epoch: 34 [50/54 (92.5925925925926%)] \t Train Loss: 0.0031693823635578155\n",
      "\n",
      " Train set: Average loss: 0.005721633788198233, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "Train Epoch: 35 [0/54 (0.0%)] \t Train Loss: 8.411883027292788e-05\n",
      "Train Epoch: 35 [10/54 (18.51851851851852%)] \t Train Loss: 9.433064260520042e-05\n",
      "Train Epoch: 35 [20/54 (37.03703703703704%)] \t Train Loss: 0.000183132232632488\n",
      "Train Epoch: 35 [30/54 (55.55555555555556%)] \t Train Loss: 0.0736461877822876\n",
      "Train Epoch: 35 [40/54 (74.07407407407408%)] \t Train Loss: 0.003994743898510933\n",
      "Train Epoch: 35 [50/54 (92.5925925925926%)] \t Train Loss: 0.002206725813448429\n",
      "\n",
      " Train set: Average loss: 0.00884439330548048, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 36 [0/54 (0.0%)] \t Train Loss: 0.0010297147557139397\n",
      "Train Epoch: 36 [10/54 (18.51851851851852%)] \t Train Loss: 0.00036029545590281485\n",
      "Train Epoch: 36 [20/54 (37.03703703703704%)] \t Train Loss: 0.00019964626990258693\n",
      "Train Epoch: 36 [30/54 (55.55555555555556%)] \t Train Loss: 0.0016783954575657844\n",
      "Train Epoch: 36 [40/54 (74.07407407407408%)] \t Train Loss: 0.0017635770142078399\n",
      "Train Epoch: 36 [50/54 (92.5925925925926%)] \t Train Loss: 0.012766610085964202\n",
      "\n",
      " Train set: Average loss: 0.011067172512412071, Accuracy: 416/425 (97.88235294117646%)\n",
      "\n",
      "Train Epoch: 37 [0/54 (0.0%)] \t Train Loss: 0.004499497264623642\n",
      "Train Epoch: 37 [10/54 (18.51851851851852%)] \t Train Loss: 0.00026284470222890375\n",
      "Train Epoch: 37 [20/54 (37.03703703703704%)] \t Train Loss: 0.01025024875998497\n",
      "Train Epoch: 37 [30/54 (55.55555555555556%)] \t Train Loss: 0.001401240285485983\n",
      "Train Epoch: 37 [40/54 (74.07407407407408%)] \t Train Loss: 0.005977291613817215\n",
      "Train Epoch: 37 [50/54 (92.5925925925926%)] \t Train Loss: 0.004816388711333275\n",
      "\n",
      " Train set: Average loss: 0.003658703761175275, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 38 [0/54 (0.0%)] \t Train Loss: 0.000977439619600773\n",
      "Train Epoch: 38 [10/54 (18.51851851851852%)] \t Train Loss: 0.0004559630993753672\n",
      "Train Epoch: 38 [20/54 (37.03703703703704%)] \t Train Loss: 0.0010263069532811641\n",
      "Train Epoch: 38 [30/54 (55.55555555555556%)] \t Train Loss: 0.00018406842136755585\n",
      "Train Epoch: 38 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009078262373805046\n",
      "Train Epoch: 38 [50/54 (92.5925925925926%)] \t Train Loss: 0.0008979940786957741\n",
      "\n",
      " Train set: Average loss: 0.00216675759293139, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "Train Epoch: 39 [0/54 (0.0%)] \t Train Loss: 0.0002488235477358103\n",
      "Train Epoch: 39 [10/54 (18.51851851851852%)] \t Train Loss: 0.0001298113726079464\n",
      "Train Epoch: 39 [20/54 (37.03703703703704%)] \t Train Loss: 0.000725699309259653\n",
      "Train Epoch: 39 [30/54 (55.55555555555556%)] \t Train Loss: 0.00044309720396995544\n",
      "Train Epoch: 39 [40/54 (74.07407407407408%)] \t Train Loss: 2.6967495796270668e-05\n",
      "Train Epoch: 39 [50/54 (92.5925925925926%)] \t Train Loss: 0.0017715705558657645\n",
      "\n",
      " Train set: Average loss: 0.014579437673091888, Accuracy: 416/425 (97.88235294117646%)\n",
      "\n",
      "Train Epoch: 40 [0/54 (0.0%)] \t Train Loss: 0.002560975030064583\n",
      "Train Epoch: 40 [10/54 (18.51851851851852%)] \t Train Loss: 0.03774880170822144\n",
      "Train Epoch: 40 [20/54 (37.03703703703704%)] \t Train Loss: 0.003360560908913612\n",
      "Train Epoch: 40 [30/54 (55.55555555555556%)] \t Train Loss: 0.0026091285049915313\n",
      "Train Epoch: 40 [40/54 (74.07407407407408%)] \t Train Loss: 0.0001571408472955227\n",
      "Train Epoch: 40 [50/54 (92.5925925925926%)] \t Train Loss: 0.011094353348016738\n",
      "\n",
      " Train set: Average loss: 0.016271958127617836, Accuracy: 403/425 (94.82352941176471%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 50 TN= 45 FN= 10 FP= 13\n",
      "TP+FP 63\n",
      "precision 0.7936507936507936\n",
      "recall 0.8333333333333334\n",
      "F1 0.8130081300813008\n",
      "acc 0.8050847457627118\n",
      "AUCp 0.8045977011494254\n",
      "AUC 0.8551724137931035\n",
      "\n",
      " The epoch is 40, average recall: 0.8333333333333334, average precision: 0.7936507936507936,average F1: 0.8130081300813008, average accuracy: 0.8050847457627118, average AUC: 0.8551724137931035\n",
      "Train Epoch: 41 [0/54 (0.0%)] \t Train Loss: 0.004255679994821548\n",
      "Train Epoch: 41 [10/54 (18.51851851851852%)] \t Train Loss: 0.0015256447717547418\n",
      "Train Epoch: 41 [20/54 (37.03703703703704%)] \t Train Loss: 0.002039429917931557\n",
      "Train Epoch: 41 [30/54 (55.55555555555556%)] \t Train Loss: 0.00036405562423169613\n",
      "Train Epoch: 41 [40/54 (74.07407407407408%)] \t Train Loss: 0.001941528357565403\n",
      "Train Epoch: 41 [50/54 (92.5925925925926%)] \t Train Loss: 0.005660473182797432\n",
      "\n",
      " Train set: Average loss: 0.008937257342040539, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 42 [0/54 (0.0%)] \t Train Loss: 0.0021855149418115614\n",
      "Train Epoch: 42 [10/54 (18.51851851851852%)] \t Train Loss: 0.01300884336233139\n",
      "Train Epoch: 42 [20/54 (37.03703703703704%)] \t Train Loss: 0.0007033044937998056\n",
      "Train Epoch: 42 [30/54 (55.55555555555556%)] \t Train Loss: 0.006481591612100601\n",
      "Train Epoch: 42 [40/54 (74.07407407407408%)] \t Train Loss: 0.0462530255317688\n",
      "Train Epoch: 42 [50/54 (92.5925925925926%)] \t Train Loss: 0.004447862878441811\n",
      "\n",
      " Train set: Average loss: 0.010890169069170952, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "Train Epoch: 43 [0/54 (0.0%)] \t Train Loss: 0.0007136506028473377\n",
      "Train Epoch: 43 [10/54 (18.51851851851852%)] \t Train Loss: 0.017020636796951295\n",
      "Train Epoch: 43 [20/54 (37.03703703703704%)] \t Train Loss: 0.0018678436055779458\n",
      "Train Epoch: 43 [30/54 (55.55555555555556%)] \t Train Loss: 0.0016971966251730919\n",
      "Train Epoch: 43 [40/54 (74.07407407407408%)] \t Train Loss: 0.0011258963495492935\n",
      "Train Epoch: 43 [50/54 (92.5925925925926%)] \t Train Loss: 0.0009131735190749168\n",
      "\n",
      " Train set: Average loss: 0.0082616051658988, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 44 [0/54 (0.0%)] \t Train Loss: 0.001469472236931324\n",
      "Train Epoch: 44 [10/54 (18.51851851851852%)] \t Train Loss: 0.00034726953599601985\n",
      "Train Epoch: 44 [20/54 (37.03703703703704%)] \t Train Loss: 0.002174695208668709\n",
      "Train Epoch: 44 [30/54 (55.55555555555556%)] \t Train Loss: 0.006180598959326744\n",
      "Train Epoch: 44 [40/54 (74.07407407407408%)] \t Train Loss: 6.670901784673333e-05\n",
      "Train Epoch: 44 [50/54 (92.5925925925926%)] \t Train Loss: 0.011315811425447464\n",
      "\n",
      " Train set: Average loss: 0.0036378582008183002, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "Train Epoch: 45 [0/54 (0.0%)] \t Train Loss: 2.4252425646409392e-05\n",
      "Train Epoch: 45 [10/54 (18.51851851851852%)] \t Train Loss: 0.0005188330076634883\n",
      "Train Epoch: 45 [20/54 (37.03703703703704%)] \t Train Loss: 0.018997634947299957\n",
      "Train Epoch: 45 [30/54 (55.55555555555556%)] \t Train Loss: 0.004646823555231094\n",
      "Train Epoch: 45 [40/54 (74.07407407407408%)] \t Train Loss: 0.0026195842772722246\n",
      "Train Epoch: 45 [50/54 (92.5925925925926%)] \t Train Loss: 0.0011676512658596039\n",
      "\n",
      " Train set: Average loss: 0.009730561636388302, Accuracy: 415/425 (97.6470588235294%)\n",
      "\n",
      "Train Epoch: 46 [0/54 (0.0%)] \t Train Loss: 0.003612673282623291\n",
      "Train Epoch: 46 [10/54 (18.51851851851852%)] \t Train Loss: 2.9666093178093432e-05\n",
      "Train Epoch: 46 [20/54 (37.03703703703704%)] \t Train Loss: 0.10357010364532471\n",
      "Train Epoch: 46 [30/54 (55.55555555555556%)] \t Train Loss: 0.024295277893543243\n",
      "Train Epoch: 46 [40/54 (74.07407407407408%)] \t Train Loss: 0.005676029622554779\n",
      "Train Epoch: 46 [50/54 (92.5925925925926%)] \t Train Loss: 0.021394413709640504\n",
      "\n",
      " Train set: Average loss: 0.01622268743813038, Accuracy: 410/425 (96.47058823529412%)\n",
      "\n",
      "Train Epoch: 47 [0/54 (0.0%)] \t Train Loss: 0.001237428281456232\n",
      "Train Epoch: 47 [10/54 (18.51851851851852%)] \t Train Loss: 0.033161970973014834\n",
      "Train Epoch: 47 [20/54 (37.03703703703704%)] \t Train Loss: 0.008077289909124374\n",
      "Train Epoch: 47 [30/54 (55.55555555555556%)] \t Train Loss: 0.0026660395786166193\n",
      "Train Epoch: 47 [40/54 (74.07407407407408%)] \t Train Loss: 0.0064627304673194885\n",
      "Train Epoch: 47 [50/54 (92.5925925925926%)] \t Train Loss: 0.006191281974315644\n",
      "\n",
      " Train set: Average loss: 0.009306664578616619, Accuracy: 417/425 (98.11764705882354%)\n",
      "\n",
      "Train Epoch: 48 [0/54 (0.0%)] \t Train Loss: 0.00024083559401333332\n",
      "Train Epoch: 48 [10/54 (18.51851851851852%)] \t Train Loss: 0.0002569120610132813\n",
      "Train Epoch: 48 [20/54 (37.03703703703704%)] \t Train Loss: 0.00011507991002872587\n",
      "Train Epoch: 48 [30/54 (55.55555555555556%)] \t Train Loss: 0.00035019731149077415\n",
      "Train Epoch: 48 [40/54 (74.07407407407408%)] \t Train Loss: 5.794764147140086e-05\n",
      "Train Epoch: 48 [50/54 (92.5925925925926%)] \t Train Loss: 0.0015232987701892854\n",
      "\n",
      " Train set: Average loss: 0.005319423507899046, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 49 [0/54 (0.0%)] \t Train Loss: 0.0005708550568670034\n",
      "Train Epoch: 49 [10/54 (18.51851851851852%)] \t Train Loss: 0.0004180684220045805\n",
      "Train Epoch: 49 [20/54 (37.03703703703704%)] \t Train Loss: 0.00019342576852068304\n",
      "Train Epoch: 49 [30/54 (55.55555555555556%)] \t Train Loss: 0.0006528929341584444\n",
      "Train Epoch: 49 [40/54 (74.07407407407408%)] \t Train Loss: 0.0012005547061562539\n",
      "Train Epoch: 49 [50/54 (92.5925925925926%)] \t Train Loss: 0.00033881058916449545\n",
      "\n",
      " Train set: Average loss: 0.006451128516346216, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 50 [0/54 (0.0%)] \t Train Loss: 0.0005916773341596126\n",
      "Train Epoch: 50 [10/54 (18.51851851851852%)] \t Train Loss: 0.00013421170879155398\n",
      "Train Epoch: 50 [20/54 (37.03703703703704%)] \t Train Loss: 0.0006016248837113381\n",
      "Train Epoch: 50 [30/54 (55.55555555555556%)] \t Train Loss: 7.657340029254556e-05\n",
      "Train Epoch: 50 [40/54 (74.07407407407408%)] \t Train Loss: 0.00389380119740963\n",
      "Train Epoch: 50 [50/54 (92.5925925925926%)] \t Train Loss: 0.01002396121621132\n",
      "\n",
      " Train set: Average loss: 0.004141937009990215, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 51 TN= 43 FN= 9 FP= 15\n",
      "TP+FP 66\n",
      "precision 0.7727272727272727\n",
      "recall 0.85\n",
      "F1 0.8095238095238095\n",
      "acc 0.7966101694915254\n",
      "AUCp 0.7956896551724139\n",
      "AUC 0.8551724137931035\n",
      "\n",
      " The epoch is 50, average recall: 0.85, average precision: 0.7727272727272727,average F1: 0.8095238095238095, average accuracy: 0.7966101694915254, average AUC: 0.8551724137931035\n",
      "Train Epoch: 51 [0/54 (0.0%)] \t Train Loss: 0.0009566783905029297\n",
      "Train Epoch: 51 [10/54 (18.51851851851852%)] \t Train Loss: 0.005110563710331917\n",
      "Train Epoch: 51 [20/54 (37.03703703703704%)] \t Train Loss: 0.0003316479502245784\n",
      "Train Epoch: 51 [30/54 (55.55555555555556%)] \t Train Loss: 0.002521197125315666\n",
      "Train Epoch: 51 [40/54 (74.07407407407408%)] \t Train Loss: 0.0023340292274951933\n",
      "Train Epoch: 51 [50/54 (92.5925925925926%)] \t Train Loss: 0.0021795181557536123\n",
      "\n",
      " Train set: Average loss: 0.017283732071518898, Accuracy: 407/425 (95.76470588235294%)\n",
      "\n",
      "Train Epoch: 52 [0/54 (0.0%)] \t Train Loss: 0.016520771384239196\n",
      "Train Epoch: 52 [10/54 (18.51851851851852%)] \t Train Loss: 0.013681699335575104\n",
      "Train Epoch: 52 [20/54 (37.03703703703704%)] \t Train Loss: 0.004460521042346954\n",
      "Train Epoch: 52 [30/54 (55.55555555555556%)] \t Train Loss: 0.0015577560290694237\n",
      "Train Epoch: 52 [40/54 (74.07407407407408%)] \t Train Loss: 0.009319235384464265\n",
      "Train Epoch: 52 [50/54 (92.5925925925926%)] \t Train Loss: 0.004692858457565308\n",
      "\n",
      " Train set: Average loss: 0.007040706463158131, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 53 [0/54 (0.0%)] \t Train Loss: 0.0029066177085042\n",
      "Train Epoch: 53 [10/54 (18.51851851851852%)] \t Train Loss: 0.0003091088030487299\n",
      "Train Epoch: 53 [20/54 (37.03703703703704%)] \t Train Loss: 0.00047217044048011305\n",
      "Train Epoch: 53 [30/54 (55.55555555555556%)] \t Train Loss: 0.010832893848419189\n",
      "Train Epoch: 53 [40/54 (74.07407407407408%)] \t Train Loss: 0.0015712570399045943\n",
      "Train Epoch: 53 [50/54 (92.5925925925926%)] \t Train Loss: 8.345377864316106e-05\n",
      "\n",
      " Train set: Average loss: 0.004678006749600172, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 54 [0/54 (0.0%)] \t Train Loss: 0.00035134879872202875\n",
      "Train Epoch: 54 [10/54 (18.51851851851852%)] \t Train Loss: 0.00027296454645693303\n",
      "Train Epoch: 54 [20/54 (37.03703703703704%)] \t Train Loss: 0.030712991952896118\n",
      "Train Epoch: 54 [30/54 (55.55555555555556%)] \t Train Loss: 0.0018876276910305024\n",
      "Train Epoch: 54 [40/54 (74.07407407407408%)] \t Train Loss: 0.09177684187889099\n",
      "Train Epoch: 54 [50/54 (92.5925925925926%)] \t Train Loss: 0.0008965877816081047\n",
      "\n",
      " Train set: Average loss: 0.01257987692952156, Accuracy: 409/425 (96.23529411764706%)\n",
      "\n",
      "Train Epoch: 55 [0/54 (0.0%)] \t Train Loss: 0.002967742085456848\n",
      "Train Epoch: 55 [10/54 (18.51851851851852%)] \t Train Loss: 0.003252634033560753\n",
      "Train Epoch: 55 [20/54 (37.03703703703704%)] \t Train Loss: 0.0001777609810233116\n",
      "Train Epoch: 55 [30/54 (55.55555555555556%)] \t Train Loss: 0.0001726015005260706\n",
      "Train Epoch: 55 [40/54 (74.07407407407408%)] \t Train Loss: 0.000525750545784831\n",
      "Train Epoch: 55 [50/54 (92.5925925925926%)] \t Train Loss: 0.00446886420249939\n",
      "\n",
      " Train set: Average loss: 0.008792330510914326, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 56 [0/54 (0.0%)] \t Train Loss: 0.0012506890110671521\n",
      "Train Epoch: 56 [10/54 (18.51851851851852%)] \t Train Loss: 0.002653513103723526\n",
      "Train Epoch: 56 [20/54 (37.03703703703704%)] \t Train Loss: 0.00723487064242363\n",
      "Train Epoch: 56 [30/54 (55.55555555555556%)] \t Train Loss: 0.0019575389102101325\n",
      "Train Epoch: 56 [40/54 (74.07407407407408%)] \t Train Loss: 0.0049272853881120685\n",
      "Train Epoch: 56 [50/54 (92.5925925925926%)] \t Train Loss: 0.005776211246848106\n",
      "\n",
      " Train set: Average loss: 0.007047994527965784, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 57 [0/54 (0.0%)] \t Train Loss: 0.0003330616280436516\n",
      "Train Epoch: 57 [10/54 (18.51851851851852%)] \t Train Loss: 0.0007243743166327477\n",
      "Train Epoch: 57 [20/54 (37.03703703703704%)] \t Train Loss: 0.005102543160319328\n",
      "Train Epoch: 57 [30/54 (55.55555555555556%)] \t Train Loss: 0.00023201117292046547\n",
      "Train Epoch: 57 [40/54 (74.07407407407408%)] \t Train Loss: 0.0005409481935203075\n",
      "Train Epoch: 57 [50/54 (92.5925925925926%)] \t Train Loss: 0.001201297901570797\n",
      "\n",
      " Train set: Average loss: 0.0014025925192981958, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 58 [0/54 (0.0%)] \t Train Loss: 0.0009847603738307952\n",
      "Train Epoch: 58 [10/54 (18.51851851851852%)] \t Train Loss: 0.00016996010672301053\n",
      "Train Epoch: 58 [20/54 (37.03703703703704%)] \t Train Loss: 0.028250229358673096\n",
      "Train Epoch: 58 [30/54 (55.55555555555556%)] \t Train Loss: 0.00022875634022057056\n",
      "Train Epoch: 58 [40/54 (74.07407407407408%)] \t Train Loss: 0.00038229317869991063\n",
      "Train Epoch: 58 [50/54 (92.5925925925926%)] \t Train Loss: 0.0002999031916260719\n",
      "\n",
      " Train set: Average loss: 0.007381667383015156, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 59 [0/54 (0.0%)] \t Train Loss: 0.00031010790262371303\n",
      "Train Epoch: 59 [10/54 (18.51851851851852%)] \t Train Loss: 0.016507482528686522\n",
      "Train Epoch: 59 [20/54 (37.03703703703704%)] \t Train Loss: 0.0005163946654647589\n",
      "Train Epoch: 59 [30/54 (55.55555555555556%)] \t Train Loss: 0.0003127566073089838\n",
      "Train Epoch: 59 [40/54 (74.07407407407408%)] \t Train Loss: 0.00039243432693183424\n",
      "Train Epoch: 59 [50/54 (92.5925925925926%)] \t Train Loss: 0.007260233163833618\n",
      "\n",
      " Train set: Average loss: 0.005868011619895697, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 60 [0/54 (0.0%)] \t Train Loss: 0.0010387842543423177\n",
      "Train Epoch: 60 [10/54 (18.51851851851852%)] \t Train Loss: 0.0007058318704366684\n",
      "Train Epoch: 60 [20/54 (37.03703703703704%)] \t Train Loss: 0.004393746703863144\n",
      "Train Epoch: 60 [30/54 (55.55555555555556%)] \t Train Loss: 0.0003129889257252216\n",
      "Train Epoch: 60 [40/54 (74.07407407407408%)] \t Train Loss: 0.0004955784417688847\n",
      "Train Epoch: 60 [50/54 (92.5925925925926%)] \t Train Loss: 0.0006865377072244883\n",
      "\n",
      " Train set: Average loss: 0.0029363033827394247, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 50 TN= 42 FN= 10 FP= 16\n",
      "TP+FP 66\n",
      "precision 0.7575757575757576\n",
      "recall 0.8333333333333334\n",
      "F1 0.7936507936507938\n",
      "acc 0.7796610169491526\n",
      "AUCp 0.7787356321839081\n",
      "AUC 0.8770114942528736\n",
      "\n",
      " The epoch is 60, average recall: 0.8333333333333334, average precision: 0.7575757575757576,average F1: 0.7936507936507938, average accuracy: 0.7796610169491526, average AUC: 0.8770114942528736\n",
      "Train Epoch: 61 [0/54 (0.0%)] \t Train Loss: 0.0007028460968285799\n",
      "Train Epoch: 61 [10/54 (18.51851851851852%)] \t Train Loss: 0.004268286749720573\n",
      "Train Epoch: 61 [20/54 (37.03703703703704%)] \t Train Loss: 0.00015020626597106457\n",
      "Train Epoch: 61 [30/54 (55.55555555555556%)] \t Train Loss: 0.0015282025560736656\n",
      "Train Epoch: 61 [40/54 (74.07407407407408%)] \t Train Loss: 0.003007232956588268\n",
      "Train Epoch: 61 [50/54 (92.5925925925926%)] \t Train Loss: 0.0017728962004184723\n",
      "\n",
      " Train set: Average loss: 0.005215614102780819, Accuracy: 418/425 (98.3529411764706%)\n",
      "\n",
      "Train Epoch: 62 [0/54 (0.0%)] \t Train Loss: 0.00021371361799538136\n",
      "Train Epoch: 62 [10/54 (18.51851851851852%)] \t Train Loss: 0.0006870872341096402\n",
      "Train Epoch: 62 [20/54 (37.03703703703704%)] \t Train Loss: 0.0011292211711406708\n",
      "Train Epoch: 62 [30/54 (55.55555555555556%)] \t Train Loss: 0.0053004961460828785\n",
      "Train Epoch: 62 [40/54 (74.07407407407408%)] \t Train Loss: 3.128585813101381e-05\n",
      "Train Epoch: 62 [50/54 (92.5925925925926%)] \t Train Loss: 9.196577593684196e-05\n",
      "\n",
      " Train set: Average loss: 0.0018159481696784496, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 63 [0/54 (0.0%)] \t Train Loss: 0.0002719249343499541\n",
      "Train Epoch: 63 [10/54 (18.51851851851852%)] \t Train Loss: 3.498895966913551e-05\n",
      "Train Epoch: 63 [20/54 (37.03703703703704%)] \t Train Loss: 0.00010462927166372537\n",
      "Train Epoch: 63 [30/54 (55.55555555555556%)] \t Train Loss: 0.0008857372216880321\n",
      "Train Epoch: 63 [40/54 (74.07407407407408%)] \t Train Loss: 0.00018943235045298934\n",
      "Train Epoch: 63 [50/54 (92.5925925925926%)] \t Train Loss: 2.2381998132914304e-05\n",
      "\n",
      " Train set: Average loss: 0.0017295385478064418, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 64 [0/54 (0.0%)] \t Train Loss: 0.00021304453257471324\n",
      "Train Epoch: 64 [10/54 (18.51851851851852%)] \t Train Loss: 0.03902205228805542\n",
      "Train Epoch: 64 [20/54 (37.03703703703704%)] \t Train Loss: 0.000168986851349473\n",
      "Train Epoch: 64 [30/54 (55.55555555555556%)] \t Train Loss: 0.00017975858645513654\n",
      "Train Epoch: 64 [40/54 (74.07407407407408%)] \t Train Loss: 0.0016460897400975226\n",
      "Train Epoch: 64 [50/54 (92.5925925925926%)] \t Train Loss: 0.004803798720240593\n",
      "\n",
      " Train set: Average loss: 0.010222411714494228, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 65 [0/54 (0.0%)] \t Train Loss: 0.005624908208847046\n",
      "Train Epoch: 65 [10/54 (18.51851851851852%)] \t Train Loss: 0.001445099525153637\n",
      "Train Epoch: 65 [20/54 (37.03703703703704%)] \t Train Loss: 0.005600958317518234\n",
      "Train Epoch: 65 [30/54 (55.55555555555556%)] \t Train Loss: 0.0013170385733246802\n",
      "Train Epoch: 65 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009388299658894539\n",
      "Train Epoch: 65 [50/54 (92.5925925925926%)] \t Train Loss: 0.00013905165251344443\n",
      "\n",
      " Train set: Average loss: 0.008632425218820572, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "Train Epoch: 66 [0/54 (0.0%)] \t Train Loss: 0.00016360635636374353\n",
      "Train Epoch: 66 [10/54 (18.51851851851852%)] \t Train Loss: 0.0003948207013309002\n",
      "Train Epoch: 66 [20/54 (37.03703703703704%)] \t Train Loss: 0.00028180242516100406\n",
      "Train Epoch: 66 [30/54 (55.55555555555556%)] \t Train Loss: 0.0002987751038745046\n",
      "Train Epoch: 66 [40/54 (74.07407407407408%)] \t Train Loss: 4.810492973774672e-05\n",
      "Train Epoch: 66 [50/54 (92.5925925925926%)] \t Train Loss: 0.0001420443062670529\n",
      "\n",
      " Train set: Average loss: 0.0019186936551705003, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 67 [0/54 (0.0%)] \t Train Loss: 0.00021769562736153602\n",
      "Train Epoch: 67 [10/54 (18.51851851851852%)] \t Train Loss: 0.0014961219392716884\n",
      "Train Epoch: 67 [20/54 (37.03703703703704%)] \t Train Loss: 0.0001388630014844239\n",
      "Train Epoch: 67 [30/54 (55.55555555555556%)] \t Train Loss: 0.00014736205339431762\n",
      "Train Epoch: 67 [40/54 (74.07407407407408%)] \t Train Loss: 0.0006890912540256977\n",
      "Train Epoch: 67 [50/54 (92.5925925925926%)] \t Train Loss: 0.00046664625406265257\n",
      "\n",
      " Train set: Average loss: 0.0010153530165553093, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 68 [0/54 (0.0%)] \t Train Loss: 5.600779550150037e-05\n",
      "Train Epoch: 68 [10/54 (18.51851851851852%)] \t Train Loss: 3.0322084785439075e-05\n",
      "Train Epoch: 68 [20/54 (37.03703703703704%)] \t Train Loss: 1.297614217037335e-05\n",
      "Train Epoch: 68 [30/54 (55.55555555555556%)] \t Train Loss: 5.1301979692652824e-05\n",
      "Train Epoch: 68 [40/54 (74.07407407407408%)] \t Train Loss: 3.04884510114789e-05\n",
      "Train Epoch: 68 [50/54 (92.5925925925926%)] \t Train Loss: 0.00016150973970070482\n",
      "\n",
      " Train set: Average loss: 0.004277749918401241, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "Train Epoch: 69 [0/54 (0.0%)] \t Train Loss: 0.00035155222285538913\n",
      "Train Epoch: 69 [10/54 (18.51851851851852%)] \t Train Loss: 0.007598623633384705\n",
      "Train Epoch: 69 [20/54 (37.03703703703704%)] \t Train Loss: 0.004283212125301361\n",
      "Train Epoch: 69 [30/54 (55.55555555555556%)] \t Train Loss: 0.00025420908350497483\n",
      "Train Epoch: 69 [40/54 (74.07407407407408%)] \t Train Loss: 0.0029103750362992286\n",
      "Train Epoch: 69 [50/54 (92.5925925925926%)] \t Train Loss: 0.00013004301581531763\n",
      "\n",
      " Train set: Average loss: 0.00882628932595253, Accuracy: 416/425 (97.88235294117646%)\n",
      "\n",
      "Train Epoch: 70 [0/54 (0.0%)] \t Train Loss: 0.025718137621879578\n",
      "Train Epoch: 70 [10/54 (18.51851851851852%)] \t Train Loss: 0.0010633852332830429\n",
      "Train Epoch: 70 [20/54 (37.03703703703704%)] \t Train Loss: 0.0004493913147598505\n",
      "Train Epoch: 70 [30/54 (55.55555555555556%)] \t Train Loss: 0.0011435552500188352\n",
      "Train Epoch: 70 [40/54 (74.07407407407408%)] \t Train Loss: 0.004631536081433296\n",
      "Train Epoch: 70 [50/54 (92.5925925925926%)] \t Train Loss: 0.008843246847391129\n",
      "\n",
      " Train set: Average loss: 0.009664761833846569, Accuracy: 412/425 (96.94117647058823%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 50 TN= 44 FN= 10 FP= 14\n",
      "TP+FP 64\n",
      "precision 0.78125\n",
      "recall 0.8333333333333334\n",
      "F1 0.8064516129032259\n",
      "acc 0.7966101694915254\n",
      "AUCp 0.7959770114942528\n",
      "AUC 0.8525862068965517\n",
      "\n",
      " The epoch is 70, average recall: 0.8333333333333334, average precision: 0.78125,average F1: 0.8064516129032259, average accuracy: 0.7966101694915254, average AUC: 0.8525862068965517\n",
      "Train Epoch: 71 [0/54 (0.0%)] \t Train Loss: 0.0007057568989694118\n",
      "Train Epoch: 71 [10/54 (18.51851851851852%)] \t Train Loss: 0.00015653540613129734\n",
      "Train Epoch: 71 [20/54 (37.03703703703704%)] \t Train Loss: 0.019057078659534453\n",
      "Train Epoch: 71 [30/54 (55.55555555555556%)] \t Train Loss: 0.006168633699417114\n",
      "Train Epoch: 71 [40/54 (74.07407407407408%)] \t Train Loss: 0.02746867835521698\n",
      "Train Epoch: 71 [50/54 (92.5925925925926%)] \t Train Loss: 0.0013464797288179398\n",
      "\n",
      " Train set: Average loss: 0.01293351873755455, Accuracy: 411/425 (96.70588235294117%)\n",
      "\n",
      "Train Epoch: 72 [0/54 (0.0%)] \t Train Loss: 0.0008836817927658558\n",
      "Train Epoch: 72 [10/54 (18.51851851851852%)] \t Train Loss: 0.0003614820074290037\n",
      "Train Epoch: 72 [20/54 (37.03703703703704%)] \t Train Loss: 0.007938577234745026\n",
      "Train Epoch: 72 [30/54 (55.55555555555556%)] \t Train Loss: 0.0004156559240072966\n",
      "Train Epoch: 72 [40/54 (74.07407407407408%)] \t Train Loss: 0.006689248979091645\n",
      "Train Epoch: 72 [50/54 (92.5925925925926%)] \t Train Loss: 0.00047550871968269346\n",
      "\n",
      " Train set: Average loss: 0.003666579956188798, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 73 [0/54 (0.0%)] \t Train Loss: 0.007379666715860367\n",
      "Train Epoch: 73 [10/54 (18.51851851851852%)] \t Train Loss: 7.661324925720692e-05\n",
      "Train Epoch: 73 [20/54 (37.03703703703704%)] \t Train Loss: 9.467887575738132e-05\n",
      "Train Epoch: 73 [30/54 (55.55555555555556%)] \t Train Loss: 0.0016859857365489005\n",
      "Train Epoch: 73 [40/54 (74.07407407407408%)] \t Train Loss: 1.4986835594754666e-05\n",
      "Train Epoch: 73 [50/54 (92.5925925925926%)] \t Train Loss: 0.00012091677635908126\n",
      "\n",
      " Train set: Average loss: 0.001484532724134624, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 74 [0/54 (0.0%)] \t Train Loss: 0.0038010910153388976\n",
      "Train Epoch: 74 [10/54 (18.51851851851852%)] \t Train Loss: 0.0049513310194015505\n",
      "Train Epoch: 74 [20/54 (37.03703703703704%)] \t Train Loss: 8.365738904103637e-05\n",
      "Train Epoch: 74 [30/54 (55.55555555555556%)] \t Train Loss: 0.00010905585950240492\n",
      "Train Epoch: 74 [40/54 (74.07407407407408%)] \t Train Loss: 0.0012361644767224789\n",
      "Train Epoch: 74 [50/54 (92.5925925925926%)] \t Train Loss: 0.00011720714392140507\n",
      "\n",
      " Train set: Average loss: 0.0024402642156928778, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 75 [0/54 (0.0%)] \t Train Loss: 7.67646124586463e-05\n",
      "Train Epoch: 75 [10/54 (18.51851851851852%)] \t Train Loss: 0.001106891967356205\n",
      "Train Epoch: 75 [20/54 (37.03703703703704%)] \t Train Loss: 0.004252149909734726\n",
      "Train Epoch: 75 [30/54 (55.55555555555556%)] \t Train Loss: 0.0008781864307820797\n",
      "Train Epoch: 75 [40/54 (74.07407407407408%)] \t Train Loss: 0.0017442766577005387\n",
      "Train Epoch: 75 [50/54 (92.5925925925926%)] \t Train Loss: 0.0009345091879367828\n",
      "\n",
      " Train set: Average loss: 0.005396307911723852, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "Train Epoch: 76 [0/54 (0.0%)] \t Train Loss: 0.00010418578749522567\n",
      "Train Epoch: 76 [10/54 (18.51851851851852%)] \t Train Loss: 6.821220158599317e-05\n",
      "Train Epoch: 76 [20/54 (37.03703703703704%)] \t Train Loss: 0.00045023029670119283\n",
      "Train Epoch: 76 [30/54 (55.55555555555556%)] \t Train Loss: 0.004775280877947807\n",
      "Train Epoch: 76 [40/54 (74.07407407407408%)] \t Train Loss: 0.00013085450045764447\n",
      "Train Epoch: 76 [50/54 (92.5925925925926%)] \t Train Loss: 0.0009054041467607022\n",
      "\n",
      " Train set: Average loss: 0.0018445247551426291, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 77 [0/54 (0.0%)] \t Train Loss: 0.002828456647694111\n",
      "Train Epoch: 77 [10/54 (18.51851851851852%)] \t Train Loss: 0.0015911774709820748\n",
      "Train Epoch: 77 [20/54 (37.03703703703704%)] \t Train Loss: 1.9272451754659415e-05\n",
      "Train Epoch: 77 [30/54 (55.55555555555556%)] \t Train Loss: 8.769535343162715e-05\n",
      "Train Epoch: 77 [40/54 (74.07407407407408%)] \t Train Loss: 0.0031743619590997698\n",
      "Train Epoch: 77 [50/54 (92.5925925925926%)] \t Train Loss: 0.0024290114641189577\n",
      "\n",
      " Train set: Average loss: 0.004967143293470144, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "Train Epoch: 78 [0/54 (0.0%)] \t Train Loss: 1.910467544803396e-05\n",
      "Train Epoch: 78 [10/54 (18.51851851851852%)] \t Train Loss: 0.0004642273299396038\n",
      "Train Epoch: 78 [20/54 (37.03703703703704%)] \t Train Loss: 0.0004740144591778517\n",
      "Train Epoch: 78 [30/54 (55.55555555555556%)] \t Train Loss: 2.444699639454484e-05\n",
      "Train Epoch: 78 [40/54 (74.07407407407408%)] \t Train Loss: 0.00014511155895888806\n",
      "Train Epoch: 78 [50/54 (92.5925925925926%)] \t Train Loss: 7.890055421739816e-05\n",
      "\n",
      " Train set: Average loss: 0.002616833196952939, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "Train Epoch: 79 [0/54 (0.0%)] \t Train Loss: 6.561377667821944e-05\n",
      "Train Epoch: 79 [10/54 (18.51851851851852%)] \t Train Loss: 3.194499586243182e-05\n",
      "Train Epoch: 79 [20/54 (37.03703703703704%)] \t Train Loss: 0.00034002733882516624\n",
      "Train Epoch: 79 [30/54 (55.55555555555556%)] \t Train Loss: 2.4413494975306095e-05\n",
      "Train Epoch: 79 [40/54 (74.07407407407408%)] \t Train Loss: 0.00047634923830628393\n",
      "Train Epoch: 79 [50/54 (92.5925925925926%)] \t Train Loss: 4.886875976808369e-05\n",
      "\n",
      " Train set: Average loss: 0.003871898166835308, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "Train Epoch: 80 [0/54 (0.0%)] \t Train Loss: 0.0008625720627605915\n",
      "Train Epoch: 80 [10/54 (18.51851851851852%)] \t Train Loss: 0.0017537962645292281\n",
      "Train Epoch: 80 [20/54 (37.03703703703704%)] \t Train Loss: 0.03539260923862457\n",
      "Train Epoch: 80 [30/54 (55.55555555555556%)] \t Train Loss: 0.0002856403822079301\n",
      "Train Epoch: 80 [40/54 (74.07407407407408%)] \t Train Loss: 0.010171808302402496\n",
      "Train Epoch: 80 [50/54 (92.5925925925926%)] \t Train Loss: 0.0001842728932388127\n",
      "\n",
      " Train set: Average loss: 0.010773439891636372, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 44 FN= 17 FP= 14\n",
      "TP+FP 57\n",
      "precision 0.7543859649122807\n",
      "recall 0.7166666666666667\n",
      "F1 0.735042735042735\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7376436781609196\n",
      "AUC 0.8508620689655173\n",
      "\n",
      " The epoch is 80, average recall: 0.7166666666666667, average precision: 0.7543859649122807,average F1: 0.735042735042735, average accuracy: 0.7372881355932204, average AUC: 0.8508620689655173\n",
      "Train Epoch: 81 [0/54 (0.0%)] \t Train Loss: 0.0013204341754317283\n",
      "Train Epoch: 81 [10/54 (18.51851851851852%)] \t Train Loss: 0.0002733206143602729\n",
      "Train Epoch: 81 [20/54 (37.03703703703704%)] \t Train Loss: 0.001215017680078745\n",
      "Train Epoch: 81 [30/54 (55.55555555555556%)] \t Train Loss: 0.0035629071295261382\n",
      "Train Epoch: 81 [40/54 (74.07407407407408%)] \t Train Loss: 0.0006728197447955608\n",
      "Train Epoch: 81 [50/54 (92.5925925925926%)] \t Train Loss: 0.00017559200059622527\n",
      "\n",
      " Train set: Average loss: 0.002901366911828518, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 82 [0/54 (0.0%)] \t Train Loss: 0.005005444586277008\n",
      "Train Epoch: 82 [10/54 (18.51851851851852%)] \t Train Loss: 0.001896030269563198\n",
      "Train Epoch: 82 [20/54 (37.03703703703704%)] \t Train Loss: 0.0002405349165201187\n",
      "Train Epoch: 82 [30/54 (55.55555555555556%)] \t Train Loss: 0.023191864788532256\n",
      "Train Epoch: 82 [40/54 (74.07407407407408%)] \t Train Loss: 0.0002555627375841141\n",
      "Train Epoch: 82 [50/54 (92.5925925925926%)] \t Train Loss: 3.424393362365663e-05\n",
      "\n",
      " Train set: Average loss: 0.00425692880526185, Accuracy: 419/425 (98.58823529411765%)\n",
      "\n",
      "Train Epoch: 83 [0/54 (0.0%)] \t Train Loss: 0.00034985665697604416\n",
      "Train Epoch: 83 [10/54 (18.51851851851852%)] \t Train Loss: 0.0068404823541641235\n",
      "Train Epoch: 83 [20/54 (37.03703703703704%)] \t Train Loss: 0.011348745226860047\n",
      "Train Epoch: 83 [30/54 (55.55555555555556%)] \t Train Loss: 0.007047291100025177\n",
      "Train Epoch: 83 [40/54 (74.07407407407408%)] \t Train Loss: 0.00015346949221566318\n",
      "Train Epoch: 83 [50/54 (92.5925925925926%)] \t Train Loss: 0.00869183912873268\n",
      "\n",
      " Train set: Average loss: 0.006492931861430407, Accuracy: 414/425 (97.41176470588235%)\n",
      "\n",
      "Train Epoch: 84 [0/54 (0.0%)] \t Train Loss: 0.00014484827406704425\n",
      "Train Epoch: 84 [10/54 (18.51851851851852%)] \t Train Loss: 0.0008347271010279656\n",
      "Train Epoch: 84 [20/54 (37.03703703703704%)] \t Train Loss: 0.0001756874145939946\n",
      "Train Epoch: 84 [30/54 (55.55555555555556%)] \t Train Loss: 0.0009007969871163368\n",
      "Train Epoch: 84 [40/54 (74.07407407407408%)] \t Train Loss: 1.6476762539241463e-05\n",
      "Train Epoch: 84 [50/54 (92.5925925925926%)] \t Train Loss: 2.188244106946513e-05\n",
      "\n",
      " Train set: Average loss: 0.0012296919012442231, Accuracy: 424/425 (99.76470588235294%)\n",
      "\n",
      "Train Epoch: 85 [0/54 (0.0%)] \t Train Loss: 0.00014510788023471832\n",
      "Train Epoch: 85 [10/54 (18.51851851851852%)] \t Train Loss: 2.2948540572542697e-05\n",
      "Train Epoch: 85 [20/54 (37.03703703703704%)] \t Train Loss: 0.00033450648188591\n",
      "Train Epoch: 85 [30/54 (55.55555555555556%)] \t Train Loss: 0.00032615987583994865\n",
      "Train Epoch: 85 [40/54 (74.07407407407408%)] \t Train Loss: 9.71905014012009e-05\n",
      "Train Epoch: 85 [50/54 (92.5925925925926%)] \t Train Loss: 0.0010970532894134521\n",
      "\n",
      " Train set: Average loss: 0.006072769407182932, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "Train Epoch: 86 [0/54 (0.0%)] \t Train Loss: 7.562815444543958e-05\n",
      "Train Epoch: 86 [10/54 (18.51851851851852%)] \t Train Loss: 0.004149395972490311\n",
      "Train Epoch: 86 [20/54 (37.03703703703704%)] \t Train Loss: 0.0008400640450417996\n",
      "Train Epoch: 86 [30/54 (55.55555555555556%)] \t Train Loss: 0.007347021251916885\n",
      "Train Epoch: 86 [40/54 (74.07407407407408%)] \t Train Loss: 0.02986345887184143\n",
      "Train Epoch: 86 [50/54 (92.5925925925926%)] \t Train Loss: 0.0005349606741219759\n",
      "\n",
      " Train set: Average loss: 0.009296117350459099, Accuracy: 411/425 (96.70588235294117%)\n",
      "\n",
      "Train Epoch: 87 [0/54 (0.0%)] \t Train Loss: 0.0007398393005132675\n",
      "Train Epoch: 87 [10/54 (18.51851851851852%)] \t Train Loss: 0.001379898376762867\n",
      "Train Epoch: 87 [20/54 (37.03703703703704%)] \t Train Loss: 0.002103334292769432\n",
      "Train Epoch: 87 [30/54 (55.55555555555556%)] \t Train Loss: 0.0002551063196733594\n",
      "Train Epoch: 87 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009231247939169406\n",
      "Train Epoch: 87 [50/54 (92.5925925925926%)] \t Train Loss: 0.0003921941388398409\n",
      "\n",
      " Train set: Average loss: 0.00324828433804214, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "Train Epoch: 88 [0/54 (0.0%)] \t Train Loss: 0.0005703506525605917\n",
      "Train Epoch: 88 [10/54 (18.51851851851852%)] \t Train Loss: 4.5069388579577205e-05\n",
      "Train Epoch: 88 [20/54 (37.03703703703704%)] \t Train Loss: 0.0005718506872653961\n",
      "Train Epoch: 88 [30/54 (55.55555555555556%)] \t Train Loss: 0.0001943458104506135\n",
      "Train Epoch: 88 [40/54 (74.07407407407408%)] \t Train Loss: 0.00015813724603503944\n",
      "Train Epoch: 88 [50/54 (92.5925925925926%)] \t Train Loss: 0.0002096440177410841\n",
      "\n",
      " Train set: Average loss: 0.0019527013646438718, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 89 [0/54 (0.0%)] \t Train Loss: 4.2282050708308815e-05\n",
      "Train Epoch: 89 [10/54 (18.51851851851852%)] \t Train Loss: 7.707889308221638e-05\n",
      "Train Epoch: 89 [20/54 (37.03703703703704%)] \t Train Loss: 0.0001451205462217331\n",
      "Train Epoch: 89 [30/54 (55.55555555555556%)] \t Train Loss: 0.00016709621995687486\n",
      "Train Epoch: 89 [40/54 (74.07407407407408%)] \t Train Loss: 2.6490178424865007e-05\n",
      "Train Epoch: 89 [50/54 (92.5925925925926%)] \t Train Loss: 2.4570056120865046e-05\n",
      "\n",
      " Train set: Average loss: 0.00616860156878829, Accuracy: 416/425 (97.88235294117646%)\n",
      "\n",
      "Train Epoch: 90 [0/54 (0.0%)] \t Train Loss: 0.025550678372383118\n",
      "Train Epoch: 90 [10/54 (18.51851851851852%)] \t Train Loss: 0.00028223509434610605\n",
      "Train Epoch: 90 [20/54 (37.03703703703704%)] \t Train Loss: 0.0009171420708298684\n",
      "Train Epoch: 90 [30/54 (55.55555555555556%)] \t Train Loss: 0.0068175017833709715\n",
      "Train Epoch: 90 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009691933169960976\n",
      "Train Epoch: 90 [50/54 (92.5925925925926%)] \t Train Loss: 0.0016208045184612275\n",
      "\n",
      " Train set: Average loss: 0.009137790650129318, Accuracy: 416/425 (97.88235294117646%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 52 TN= 43 FN= 8 FP= 15\n",
      "TP+FP 67\n",
      "precision 0.7761194029850746\n",
      "recall 0.8666666666666667\n",
      "F1 0.8188976377952756\n",
      "acc 0.8050847457627118\n",
      "AUCp 0.8040229885057473\n",
      "AUC 0.9022988505747127\n",
      "\n",
      " The epoch is 90, average recall: 0.8666666666666667, average precision: 0.7761194029850746,average F1: 0.8188976377952756, average accuracy: 0.8050847457627118, average AUC: 0.9022988505747127\n",
      "Train Epoch: 91 [0/54 (0.0%)] \t Train Loss: 0.0005748960189521313\n",
      "Train Epoch: 91 [10/54 (18.51851851851852%)] \t Train Loss: 0.00017176958499476314\n",
      "Train Epoch: 91 [20/54 (37.03703703703704%)] \t Train Loss: 0.020447936654090882\n",
      "Train Epoch: 91 [30/54 (55.55555555555556%)] \t Train Loss: 0.0005542835686355829\n",
      "Train Epoch: 91 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009945866651833058\n",
      "Train Epoch: 91 [50/54 (92.5925925925926%)] \t Train Loss: 0.0003020287724211812\n",
      "\n",
      " Train set: Average loss: 0.005184291861951351, Accuracy: 422/425 (99.29411764705883%)\n",
      "\n",
      "Train Epoch: 92 [0/54 (0.0%)] \t Train Loss: 0.00015343151753768324\n",
      "Train Epoch: 92 [10/54 (18.51851851851852%)] \t Train Loss: 6.931010284461081e-05\n",
      "Train Epoch: 92 [20/54 (37.03703703703704%)] \t Train Loss: 0.000292161968536675\n",
      "Train Epoch: 92 [30/54 (55.55555555555556%)] \t Train Loss: 0.0002144965808838606\n",
      "Train Epoch: 92 [40/54 (74.07407407407408%)] \t Train Loss: 0.0003437178675085306\n",
      "Train Epoch: 92 [50/54 (92.5925925925926%)] \t Train Loss: 0.0004121532663702965\n",
      "\n",
      " Train set: Average loss: 0.008653000928461552, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "Train Epoch: 93 [0/54 (0.0%)] \t Train Loss: 0.0015582913532853127\n",
      "Train Epoch: 93 [10/54 (18.51851851851852%)] \t Train Loss: 0.04030658602714539\n",
      "Train Epoch: 93 [20/54 (37.03703703703704%)] \t Train Loss: 0.0006934446282684803\n",
      "Train Epoch: 93 [30/54 (55.55555555555556%)] \t Train Loss: 0.0016899365931749345\n",
      "Train Epoch: 93 [40/54 (74.07407407407408%)] \t Train Loss: 0.04751289486885071\n",
      "Train Epoch: 93 [50/54 (92.5925925925926%)] \t Train Loss: 0.001728660799562931\n",
      "\n",
      " Train set: Average loss: 0.01993103325366974, Accuracy: 408/425 (96.0%)\n",
      "\n",
      "Train Epoch: 94 [0/54 (0.0%)] \t Train Loss: 0.0028504474088549615\n",
      "Train Epoch: 94 [10/54 (18.51851851851852%)] \t Train Loss: 0.00031148800626397134\n",
      "Train Epoch: 94 [20/54 (37.03703703703704%)] \t Train Loss: 0.0002333188895136118\n",
      "Train Epoch: 94 [30/54 (55.55555555555556%)] \t Train Loss: 0.0034699738025665283\n",
      "Train Epoch: 94 [40/54 (74.07407407407408%)] \t Train Loss: 0.0031998686492443083\n",
      "Train Epoch: 94 [50/54 (92.5925925925926%)] \t Train Loss: 0.0013456915505230427\n",
      "\n",
      " Train set: Average loss: 0.008551682345569134, Accuracy: 413/425 (97.17647058823529%)\n",
      "\n",
      "Train Epoch: 95 [0/54 (0.0%)] \t Train Loss: 0.018895600736141206\n",
      "Train Epoch: 95 [10/54 (18.51851851851852%)] \t Train Loss: 0.0008765258826315403\n",
      "Train Epoch: 95 [20/54 (37.03703703703704%)] \t Train Loss: 0.002673163637518883\n",
      "Train Epoch: 95 [30/54 (55.55555555555556%)] \t Train Loss: 0.0004965536762028932\n",
      "Train Epoch: 95 [40/54 (74.07407407407408%)] \t Train Loss: 0.0009689945727586746\n",
      "Train Epoch: 95 [50/54 (92.5925925925926%)] \t Train Loss: 0.00062941899523139\n",
      "\n",
      " Train set: Average loss: 0.004641578532755375, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "Train Epoch: 96 [0/54 (0.0%)] \t Train Loss: 0.06789814829826354\n",
      "Train Epoch: 96 [10/54 (18.51851851851852%)] \t Train Loss: 0.0035852305591106415\n",
      "Train Epoch: 96 [20/54 (37.03703703703704%)] \t Train Loss: 6.382947904057801e-05\n",
      "Train Epoch: 96 [30/54 (55.55555555555556%)] \t Train Loss: 0.00048006433062255385\n",
      "Train Epoch: 96 [40/54 (74.07407407407408%)] \t Train Loss: 3.353265929035842e-05\n",
      "Train Epoch: 96 [50/54 (92.5925925925926%)] \t Train Loss: 9.681411320343614e-05\n",
      "\n",
      " Train set: Average loss: 0.014712352305650711, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "Train Epoch: 97 [0/54 (0.0%)] \t Train Loss: 0.0003805209882557392\n",
      "Train Epoch: 97 [10/54 (18.51851851851852%)] \t Train Loss: 0.2097485303878784\n",
      "Train Epoch: 97 [20/54 (37.03703703703704%)] \t Train Loss: 0.00010292474180459977\n",
      "Train Epoch: 97 [30/54 (55.55555555555556%)] \t Train Loss: 0.001835169456899166\n",
      "Train Epoch: 97 [40/54 (74.07407407407408%)] \t Train Loss: 0.0018306542187929153\n",
      "Train Epoch: 97 [50/54 (92.5925925925926%)] \t Train Loss: 0.0014525352977216243\n",
      "\n",
      " Train set: Average loss: 0.011376268230378628, Accuracy: 412/425 (96.94117647058823%)\n",
      "\n",
      "Train Epoch: 98 [0/54 (0.0%)] \t Train Loss: 0.004100691154599189\n",
      "Train Epoch: 98 [10/54 (18.51851851851852%)] \t Train Loss: 0.0004971347749233246\n",
      "Train Epoch: 98 [20/54 (37.03703703703704%)] \t Train Loss: 0.007898163050413132\n",
      "Train Epoch: 98 [30/54 (55.55555555555556%)] \t Train Loss: 0.0007610582746565342\n",
      "Train Epoch: 98 [40/54 (74.07407407407408%)] \t Train Loss: 0.005770407989621163\n",
      "Train Epoch: 98 [50/54 (92.5925925925926%)] \t Train Loss: 0.0003055863780900836\n",
      "\n",
      " Train set: Average loss: 0.003940218593925238, Accuracy: 421/425 (99.05882352941177%)\n",
      "\n",
      "Train Epoch: 99 [0/54 (0.0%)] \t Train Loss: 8.616660488769412e-05\n",
      "Train Epoch: 99 [10/54 (18.51851851851852%)] \t Train Loss: 0.00019268126925453544\n",
      "Train Epoch: 99 [20/54 (37.03703703703704%)] \t Train Loss: 0.01265607327222824\n",
      "Train Epoch: 99 [30/54 (55.55555555555556%)] \t Train Loss: 0.0008776845410466194\n",
      "Train Epoch: 99 [40/54 (74.07407407407408%)] \t Train Loss: 7.699907291680574e-05\n",
      "Train Epoch: 99 [50/54 (92.5925925925926%)] \t Train Loss: 0.011936599761247635\n",
      "\n",
      " Train set: Average loss: 0.0031956930179148912, Accuracy: 423/425 (99.52941176470588%)\n",
      "\n",
      "Train Epoch: 100 [0/54 (0.0%)] \t Train Loss: 0.00022564234677702188\n",
      "Train Epoch: 100 [10/54 (18.51851851851852%)] \t Train Loss: 0.00047615710645914077\n",
      "Train Epoch: 100 [20/54 (37.03703703703704%)] \t Train Loss: 0.00048366645351052286\n",
      "Train Epoch: 100 [30/54 (55.55555555555556%)] \t Train Loss: 0.011048568785190583\n",
      "Train Epoch: 100 [40/54 (74.07407407407408%)] \t Train Loss: 0.00017631410155445338\n",
      "Train Epoch: 100 [50/54 (92.5925925925926%)] \t Train Loss: 0.007677977532148361\n",
      "\n",
      " Train set: Average loss: 0.004497218877077103, Accuracy: 420/425 (98.82352941176471%)\n",
      "\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 52 TN= 47 FN= 8 FP= 11\n",
      "TP+FP 63\n",
      "precision 0.8253968253968254\n",
      "recall 0.8666666666666667\n",
      "F1 0.8455284552845528\n",
      "acc 0.8389830508474576\n",
      "AUCp 0.8385057471264367\n",
      "AUC 0.9232758620689655\n",
      "\n",
      " The epoch is 100, average recall: 0.8666666666666667, average precision: 0.8253968253968254,average F1: 0.8455284552845528, average accuracy: 0.8389830508474576, average AUC: 0.9232758620689655\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # #if epoch == total_epoch:\n",
    "        # torch.save(model.state_dict(), \"model_backup/{}.pt\".format(modelname))  \n",
    "        \n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {}, average precision: {},average F1: {}, average accuracy: {}, average AUC: {}'.format(epoch, r, p, F1, acc, AUC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vbFninNd9FfC"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "           \n",
    "    return targetlist, scorelist, predlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3VNU5IGB_Zz",
    "outputId": "89d44f19-6702-4ff2-d7a5-464a970a976a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 10, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 20, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 30, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 40, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 50, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 60, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 70, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 80, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 90, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "------------------------------\n",
      "TP= 77 TN= 76 FN= 21 FP= 29\n",
      "TP+FP 106\n",
      "precision 0.7264150943396226\n",
      "recall 0.7857142857142857\n",
      "F1 0.7549019607843137\n",
      "acc 0.7536945812807881\n",
      "AUC 0.8549076773566568\n",
      "\n",
      " vote_pred [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " The epoch is 100, average recall: 0.7857142857142857, average precision: 0.7264150943396226,average F1: 0.7549019607843137, average accuracy: 0.7536945812807881, average AUC: 0.8549076773566568\n"
     ]
    }
   ],
   "source": [
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    \n",
    "    targetlist, scorelist, predlist = test(epoch)\n",
    "#     print('target',targetlist)\n",
    "#     print('score',scorelist)\n",
    "#     print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "    \n",
    "    TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "    TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "    FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "    FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "    print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "    print('TP+FP',TP+FP)\n",
    "    p = TP / (TP + FP)\n",
    "    print('precision',p)\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    print('recall',r)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print('F1',F1)\n",
    "    print('acc',acc)\n",
    "    AUC = roc_auc_score(targetlist, vote_score)\n",
    "    print('AUC', AUC)\n",
    "    print(30*'-')\n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        \n",
    "\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "        vote_pred = np.zeros((1,testset.__len__()))\n",
    "        vote_score = np.zeros(testset.__len__())\n",
    "        print('\\n vote_pred',vote_pred)\n",
    "        print('\\n The epoch is {}, average recall: {}, average precision: {},average F1: {}, average accuracy: {}, average AUC: {}'.format(epoch, r, p, F1, acc, AUC))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part02.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
